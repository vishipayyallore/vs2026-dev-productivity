# Prompt Engineering Part 1: Introduction to Prompt Engineering

## 1. What are we doing today?

> 1. Prompt Engineering Techniques
>    - Single Turn
>    - Iterative
>    - Conversational
>    - Role play
>    - Zero Shot
>    - Single Shot
>    - Few Shots
>    - CoT
> 1. Trying our own completion examples in Azure AI Studio
> 1. Trying our own completion examples using Postman
> 1. Trying our own completion examples using `C#`
> 1. SUMMARY / RECAP / Q&A

## 2. What is prompt engineering?

Prompt engineering is an essential practice when working with language models like those offered by Azure OpenAI. It revolves around the concept of creating, refining, and optimizing input prompts to elicit specific and desired outputs from these models.

### 2.1 Core concept

At its core, prompt engineering involves carefully crafting the input that you provide to a language model. The aim is to guide the model's output, making it more accurate, relevant, and aligned with the desired outcome.

### 2.2 Why it matters

Since language models generate text based on the prompts they receive, the quality, structure, and clarity of the prompt significantly affect the output. This is why prompt engineering is crucial for tasks that require high precision and contextual relevance.

## 3. Components of effective prompt engineering

### 3.1 Clarity

The prompt should be clear and unambiguous so that the model understands the task and generates relevant outputs.

### 3.2 Specificity

Providing detailed instructions within the prompt can help the model focus on what is most important, reducing the likelihood of irrelevant or off-topic responses.

### 3.3 Context

Adding context to the prompt can significantly improve the model’s ability to generate appropriate responses. Context can include background information, examples, or specific constraints.

### 3.4 Formatting

Specifying the format of the desired output (for example, bullet points, paragraphs, or a specific structure) can help guide the model to produce text that is easier to use.

## 4. Techniques in prompt engineering

### 4.1 Example-based prompting

Provide examples within the prompt to show the model what kind of response is expected. This is especially useful for complex tasks.

### 4.2 Zero-shot, few-shot, and many-shot prompting

Use no examples (zero-shot), a few examples (few-shot), or many examples (many-shot) to influence responses based on the number and quality of examples provided.

### 4.3 Iterative refinement

Continuously refine prompts based on the outputs generated by the model. This usually involves trial and error, tweaking the prompt to get closer to the desired output.

## 5. Best practices for text-based prompt engineering

### 5.1 Be explicit

The more explicit and detailed your prompt, the better the model can align its output with your expectations.

### 5.2 Test and iterate

Start with a basic prompt and refine it based on the results. Use iterative testing to improve the model’s performance.

### 5.3 Leverage context

Whenever possible, include context that can help the model understand the nuances of the task.

### 5.4 Monitor and adjust

Regularly monitor the outputs and adjust your prompts to address any inaccuracies or undesired behaviors.

> In the context of Azure OpenAI, prompt engineering is about using these techniques to maximize the efficiency and effectiveness of AI-driven text generation, making it a powerful tool for developers and content creators alike.

## 6. Example prompts for hands-on practice

Use these prompts when trying out completions in Azure AI Studio, Postman, or your own code.

```text
Input: Please write a Happy Birthday wish for my mother.

Input: Give the top 5 food items from South India.

Input: Give the top 5 populated states in India.

Input:
1. Which is the tallest building in the world?
2. Which is the tallest building in Hyderabad?

Input: Tell me two jokes about simple people.

Input: Write a promotional email for a new wildlife rescue, including the following:
- Rescue name is Contoso
- It specializes in elephants, as well as zebras and giraffes
- Call for donations to be given at our website

Include a list of the current animals we have at our rescue after the signature, in the form of a table. These animals include elephants, zebras, gorillas, lizards, and jackrabbits.
```

## Prompt Engineering Techniques

> 1. Discussion and Demo

### Single Turn

> 1. Discussion and Demo
> 1. One clear request, answered in a single response.

**Example prompt (single turn):**

```text
You are a helpful assistant.

Explain the difference between synchronous and asynchronous programming in simple terms,
using one short paragraph and one real-world analogy.
```

### Iterative

> 1. Discussion and Demo
> 1. Refine the answer over multiple turns based on feedback.

**Example prompts (iterative):**

```text
User (step 1):
Summarize the benefits of using cloud computing for a small retail business.

User (step 2):
Great. Now shorten that summary to 3 bullet points.

User (step 3):
Nice. Rewrite the bullets so they are suitable for an executive slide.
```

### Conversational

> 1. Discussion and Demo
> 1. Memory / context between completions vs. chat

**Example prompts (conversational):**

```text
User:
I am planning to learn data engineering. Can you suggest a learning roadmap?

User (later in the same chat):
Thanks. Based on that roadmap, can you create a 4-week study plan for me?

User (later):
This is great. Now generate a short motivational message I can read every morning
to stay committed to this 4-week plan.
```

**Another example (conversational, JSON chat format):**

```json
[
 {
  "role": "system",
  "content": "You are a helpful assistant, teaching people about AI."
 },
 {
  "role": "user",
  "content": "Does Azure OpenAI support multiple languages?"
 },
 {
  "role": "assistant",
  "content": "Yes, Azure OpenAI supports several languages, and can translate between them."
 },
 {
  "role": "user",
  "content": "Do other Azure AI Services support translation too?"
 }
]
```

### Role play

> 1. Discussion and Demo
> 1. Assigning a specific role to the model (e.g., `Cardiologist` versus generic `Assistant`) changes how it interprets and responds to prompts.
> 1. Example: Asking "What is `TV`?" to a Cardiologist vs. a general Assistant will yield different responses based on the role's context.

**Example prompt (role play with system message):**

```json
[
 {
  "role": "system",
  "content": "You are an assistant designed to write intriguing job descriptions. "
 },
 {
  "role": "user",
  "content": "Write a job description for the following job title: 'Business Intelligence Analyst'. It should include responsibilities, required qualifications, and highlight benefits like time off and flexible hours."
 }
]
```

### Zero Shot

> 1. Discussion and Demo
> 1. No examples are given in the prompt.

**Example prompt (zero-shot):**

```text
You are an expert travel guide.

Suggest a 3-day itinerary for a family visiting Singapore for the first time. Include:
- Sightseeing recommendations
- Local food suggestions
- Tips for getting around the city
```

### Single Shot

> 1. Discussion and Demo
> 1. Exactly one example is given before the real question.

**Example prompt (single-shot):**

```text
Example:
Input: List the top 3 programming languages for web development.
Output:
1. JavaScript
2. TypeScript
3. Python

Now you:
Input: List the top 3 programming languages for data science.
Output:
```

### Few Shots

> 1. Discussion and Demo
> 1. A few input/output examples are shown to set the pattern.

**Example prompt (few-shot):**

```text
Convert each user request into a short, friendly email subject line.

Example 1
Request: Please confirm your attendance for the quarterly review meeting.
Subject: Confirmation needed: Quarterly review meeting

Example 2
Request: We are launching our new analytics dashboard next week.
Subject: Get ready for our new analytics dashboard

Now you:
Request: We have scheduled maintenance this weekend that may cause brief downtime.
Subject:
```

**Another example (few-shot classification):**

```text
Classify the following news headline into 1 of the following categories:
Business, Tech, Politics, Sport, Entertainment

Headline 1: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective
Category: Entertainment

Headline 2: Major Retailer Announces Plans to Close Over 100 Stores
Category:
```

### CoT (Chain of Thought)

> 1. Discussion and Demo
> 1. Chain of Thought (CoT) is a problem-solving approach that involves breaking down a complex problem into a series of smaller, logical steps or intermediate reasoning points. This method helps ensure a clear and systematic progression from the initial conditions to the final solution, enhancing accuracy and understanding by explicitly documenting the thought process at each stage.
> 1. Prompts designed to encourage Chain of Thought (CoT) reasoning explicitly ask the model to show its work step-by-step.

**Example prompt (Chain of Thought):**

```text
Please solve the following problem using a Chain of Thought (CoT) approach, which involves breaking the problem down into smaller, logical steps to ensure a clear and systematic progression to the solution. Show each intermediate step and explain your reasoning.

Problem: A bakery had 50 cupcakes. They sold 15 in the morning and then baked 20 more in the afternoon. How many cupcakes do they have now?
```

**Expected CoT Response:**

1. Start with the initial number of cupcakes: 50.
2. Subtract the number of cupcakes sold in the morning: 50 - 15 = 35.
3. Add the number of cupcakes baked in the afternoon: 35 + 20 = 55.
4. The bakery now has 55 cupcakes.

**Another example (few-shot Chain of Thought):**

```text
Solve each problem step-by-step, showing your work.

Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?

A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.

Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?
```

---

## SUMMARY / RECAP / Q&A

### Key Takeaways

1. **Clarity and Specificity**: Clear, detailed prompts produce better results than vague requests.
2. **Context Matters**: Providing relevant context helps the model understand nuances and generate appropriate responses.
3. **Technique Selection**: Choose the right technique for your task:
   - **Single Turn**: Simple, one-time requests
   - **Iterative**: Refining outputs through multiple interactions
   - **Conversational**: Building on previous context in a chat
   - **Role Play**: Assigning specific roles for specialized responses
   - **Zero Shot**: No examples needed for straightforward tasks
   - **Single/Few Shot**: Providing examples to guide the model's output format
   - **Chain of Thought**: Breaking down complex problems into steps for better accuracy

4. **Best Practices**:
   - Be explicit about what you want
   - Test and iterate on your prompts
   - Leverage context whenever possible
   - Monitor outputs and adjust as needed

### Next Steps

- Practice with the example prompts in Azure AI Studio
- Try implementing completions using Postman
- Integrate prompt engineering into your C# applications
- Experiment with different techniques to see which work best for your use cases

---
